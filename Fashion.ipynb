{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train) , (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = set()\n",
    "fig, ax = plt.subplots(5, 2, figsize = (25, 25))\n",
    "fig.tight_layout()\n",
    "for x, y in zip(X_train, Y_train):\n",
    "    if y not in done:\n",
    "        done.add(y)\n",
    "        ax[y % 5, y // 5].imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNNClassifier:\n",
    "    def __init__(self, N, L, activation='ReLU', optimizer='adam', weight_decay=0.0001, batch_size=200, learning_rate=0.001, num_epochs=200, weight_init='random'):\n",
    "        self.activation = activation # 'identity', 'logistic', 'tanh', 'relu'\n",
    "        self.optimizer = optimizer # 'normal', 'sgd', 'momentum', 'nesterov', 'rmsprop', 'adam', 'nadam'\n",
    "        self.weight_decay = weight_decay # L2 regularization hyperparameter\n",
    "        self.batch_size = batch_size # Batch size\n",
    "        self.learning_rate = learning_rate # Learning Rate\n",
    "        self.num_epochs = num_epochs # Number of epochs\n",
    "        self.weight_init = weight_init # 'random', 'xavier'\n",
    "        self.n = 100\n",
    "        self.K = 10\n",
    "        self.L = L\n",
    "        self.N = N\n",
    "        self.layer_sizes = np.zeros((L + 2))\n",
    "        self.layer_sizes[1 : L + 1] = N\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        self.a = []\n",
    "        self.h = []\n",
    "    \n",
    "    def act(self, z):\n",
    "        if(self.activation == 'sigmoid'):\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        elif(self.activation == 'tanh'):\n",
    "            return np.tanh(z)\n",
    "        elif(self.activation == 'ReLU'):\n",
    "            return np.maximum(z, np.zeros(z.shape)) \n",
    "    \n",
    "    def deriv_act(self, z):\n",
    "        if(self.activation == 'sigmoid'):\n",
    "            return 1 / (2 + np.exp(-z) + np.exp(z))\n",
    "        elif(self.activation == 'tanh'):\n",
    "            return np.cosh(z) ** -2\n",
    "        elif(self.activation == 'ReLU'):\n",
    "            return np.maximum(np.sign(z), np.zeros(z.shape))\n",
    "    \n",
    "    def oact(self, z):\n",
    "        return np.exp(z) / np.exp(z).sum(axis=0)\n",
    "    \n",
    "    def forward_prop(self, X):\n",
    "        self.a = [ np.zeros((1, 1))]\n",
    "        self.h = [X]\n",
    "        \n",
    "        for i in range(1, self.L + 1):\n",
    "            self.a.append( (self.b[i].T + (self.W[i].T @ self.h[i - 1]).T).T )\n",
    "            self.h.append(self.act(self.a[i]))\n",
    "        self.h[-1] = self.oact(self.a[-1])\n",
    "        return self.h[-1]\n",
    "    \n",
    "    def back_prop(self, Y_pred):\n",
    "        self.gradW, self.gradB, self.grada = [], [], []\n",
    "        self.gradh = [ np.zeros((1, 1))]\n",
    "        self.grada.append(-(self.ey - Y_pred))\n",
    "        for i in range (self.L, 0, -1):\n",
    "            self.gradW.append((self.grada[self.L - i] @ self.h[i - 1].T).T)\n",
    "            #print('-------------------------')\n",
    "            #print(self.grada[self.L - i])\n",
    "            #print(self.h[i - 1].T)\n",
    "            #print(self.grada[self.L - i] @ self.h[i - 1].T)\n",
    "            self.gradB.append(self.grada[self.L - i].sum(axis=1))\n",
    "            self.gradh.append(self.W[i] @ self.grada[self.L - i])\n",
    "            self.grada.append( self.gradh[self.L - i + 1] * self.deriv_act(self.a[i - 1]))\n",
    "        \n",
    "        self.gradW.append(np.zeros((self.N, self.N)))\n",
    "        self.gradB.append(np.zeros(self.N))\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def wb_init(self, num):\n",
    "        if(self.weight_init == 'random'):\n",
    "            self.W = [1 + 10 * np.random.rand(self.N, self.N) for _ in range(0, self.L)]\n",
    "            self.b = [1 + 10 * np.random.rand(self.N) for _ in range(0, self.L)]\n",
    "            self.W.append(1 + 10 * np.random.rand(self.N, self.K))\n",
    "            self.W[1] = 1 + 10 * np.random.rand(num, self.W[1].shape[1])\n",
    "            self.b.append(1 + 10 * np.random.rand(self.K))\n",
    "    \n",
    "    def grad_desc(self, X, Y):\n",
    "        \n",
    "        self.wb_init(X.shape[0])\n",
    "        \n",
    "        update_W, update_b = self.W, self.b\n",
    "        v_W, v_b = self.W, self.b\n",
    "        m_W, m_b = self.W, self.b\n",
    "        \n",
    "        \n",
    "        for t in range(1, self.num_epochs + 1):\n",
    "            \n",
    "            Y_pred = self.forward_prop(X)\n",
    "            \n",
    "            print('---------------------- a')\n",
    "            print(self.a)\n",
    "            print('---------------------- h')\n",
    "            print(self.h)\n",
    "            \n",
    "            #print(Y_pred)\n",
    "            \n",
    "            if(self.optimizer == 'nesterov'):\n",
    "                W , b = self.W, self.b\n",
    "                ngamma = 0.9 # Hyperparameter\n",
    "                self.W = [u - ngamma * v for u, v in zip(self.W, update_W)]\n",
    "                self.b = [u - ngamma * v for u, v in zip(self.b, update_b)]\n",
    "            \n",
    "            self.back_prop(Y_pred)\n",
    "            \n",
    "            #print('---------------------- gW')\n",
    "            #print(self.gradW)\n",
    "            #print('---------------------- gB')\n",
    "            #print(self.gradB)\n",
    "            \n",
    "            dW = self.gradW[::-1]\n",
    "            db = self.gradB[::-1]\n",
    "            \n",
    "            if(self.optimizer == 'normal'):\n",
    "                update_W = [self.learning_rate * u for u in dW]\n",
    "                update_b = [self.learning_rate * u for u in db]\n",
    "                \n",
    "            #elif(self.optimizer == 'sgd'):\n",
    "\n",
    "                \n",
    "            elif(self.optimizer == 'momentum'):\n",
    "                mgamma = 0.9 # Hyperparameter\n",
    "                update_W = [mgamma * u + self.learning_rate * v for u, v in zip(update_W, dW)]\n",
    "                update_b = [mgamma * u + self.learning_rate * v for u, v in zip(update_b, db)]\n",
    "            \n",
    "            elif(self.optimizer == 'nesterov'):\n",
    "                self.W, self.b = W, b\n",
    "                update_W = [ngamma * u + self.learning_rate * v for u, v in zip(update_W, dW)]\n",
    "                update_b = [ngamma * u + self.learning_rate * v for u, v in zip(update_b, db)]\n",
    "            \n",
    "            elif(self.optimizer == 'rmsprop'):\n",
    "                rbeta = 0.9\n",
    "                epsilon = 0.1\n",
    "                v_W = [rbeta * u + (1 - rbeta) * (v ** 2) for u, v in zip(v_W, dW)]\n",
    "                v_b = [rbeta * u + (1 - rbeta) * (v ** 2) for u, v in zip(v_b, db)]\n",
    "                update_W = [(self.learning_rate * u) / np.sqrt(v + epsilon) for u, v in zip(dW, v_W)]\n",
    "                update_b = [(self.learning_rate * u) / np.sqrt(v + epsilon) for u, v in zip(db, v_b)]\n",
    "                \n",
    "            elif(self.optimizer == 'adam'):\n",
    "                abeta1 = 0.99\n",
    "                abeta2 = 0.999\n",
    "                epsilon = 0.1\n",
    "                m_W = [abeta1 * u + (1 - abeta1) * v for u, v in zip(m_W, dW)]\n",
    "                m_b = [abeta1 * u + (1 - abeta1) * v for u, v in zip(m_b, db)]\n",
    "                v_W = [abeta2 * u + (1 - abeta2) * (v ** 2) for u, v in zip(v_W, dW)]\n",
    "                v_b = [abeta2 * u + (1 - abeta2) * (v ** 2) for u, v in zip(v_b, db)]\n",
    "                update_W = [( (self.learning_rate * u) / (1 - abeta1 ** t) ) / np.sqrt( (v / (1 - abeta2 ** t)) + epsilon) for u, v in zip(m_W, v_W)]\n",
    "                update_b = [( (self.learning_rate * u) / (1 - abeta1 ** t) ) / np.sqrt( (v / (1 - abeta2 ** t)) + epsilon) for u, v in zip(m_b, v_b)]\n",
    "                 \n",
    "            elif(self.optimizer == 'nadam'):\n",
    "                nbeta1 = 0.99\n",
    "                nbeta2 = 0.999\n",
    "                epsilon = 0.1\n",
    "                m_W = [nbeta1 * u + (1 - nbeta1) * v for u, v in zip(m_W, dW)]\n",
    "                m_b = [nbeta1 * u + (1 - nbeta1) * v for u, v in zip(m_b, db)]\n",
    "                v_W = [nbeta2 * u + (1 - nbeta2) * (v ** 2) for u, v in zip(v_W, dW)]\n",
    "                v_b = [nbeta2 * u + (1 - nbeta2) * (v ** 2) for u, v in zip(v_b, db)]\n",
    "                update_W = [(self.learning_rate * (nbeta1 * u + (1 - nbeta1) * v)) / (1 - nbeta1 ** t) for u, v in zip(m_W, dW)]\n",
    "                update_W = [ (u) / np.sqrt( (v / (1 - nbeta2 ** t)) + epsilon) for u, v in zip(m_W, v_W)]\n",
    "                update_b = [(self.learning_rate * (nbeta1 * u + (1 - nbeta1) * v)) / (1 - nbeta1 ** t) for u, v in zip(m_b, db)]\n",
    "                update_b = [ (u) / np.sqrt( (v / (1 - nbeta2 ** t)) + epsilon) for u, v in zip(m_b, v_b)]\n",
    "            \n",
    "            self.W = [u - v for u, v in zip(self.W, update_W)]\n",
    "            self.b = [u - v for u, v in zip(self.b, update_b)]\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        n, N = X_train.shape\n",
    "        K = np.max(Y_train) # Y_train must have values from 1 to K\n",
    "        self.layer_sizes[self.L - 1] = K\n",
    "        self.K = K\n",
    "        self.ey = np.zeros((K, n))\n",
    "        rows = np.arange(n)\n",
    "        self.ey[Y_train - 1, rows] = 1\n",
    "        self.grad_desc(X_train.T, Y_train.T)\n",
    "        \n",
    "    def predict_proba(self, X_test):\n",
    "        #print(self.W)\n",
    "        #print(self.b)\n",
    "        return self.forward_prop(X_test.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- a\n",
      "[array([[0.]]), array([[ 50.41552972,  94.14844895,  77.45568438, 101.84767242,\n",
      "        102.55456701,  56.14639402,  71.06483783,  76.4802938 ,\n",
      "         85.05140473,  89.2164548 ,  87.90807789, 104.64285583,\n",
      "         54.46906784,  46.97835091,  83.48409021]]), array([[ 8.37331925,  8.37331925,  8.37331925,  8.37331925,  8.37331925,\n",
      "         8.37331925,  8.37331925,  8.37331925,  8.37331925,  8.37331925,\n",
      "         8.37331925,  8.37331925,  8.37331925,  8.37331925,  8.37331925],\n",
      "       [14.86273581, 14.86273581, 14.86273581, 14.86273581, 14.86273581,\n",
      "        14.86273581, 14.86273581, 14.86273581, 14.86273581, 14.86273581,\n",
      "        14.86273581, 14.86273581, 14.86273581, 14.86273581, 14.86273581],\n",
      "       [11.76634824, 11.76634824, 11.76634824, 11.76634824, 11.76634824,\n",
      "        11.76634824, 11.76634824, 11.76634824, 11.76634824, 11.76634824,\n",
      "        11.76634824, 11.76634824, 11.76634824, 11.76634824, 11.76634824],\n",
      "       [12.36409909, 12.36409909, 12.36409909, 12.36409909, 12.36409909,\n",
      "        12.36409909, 12.36409909, 12.36409909, 12.36409909, 12.36409909,\n",
      "        12.36409909, 12.36409909, 12.36409909, 12.36409909, 12.36409909],\n",
      "       [ 7.84720217,  7.84720217,  7.84720217,  7.84720217,  7.84720217,\n",
      "         7.84720217,  7.84720217,  7.84720217,  7.84720217,  7.84720217,\n",
      "         7.84720217,  7.84720217,  7.84720217,  7.84720217,  7.84720217],\n",
      "       [ 4.75645529,  4.75645529,  4.75645529,  4.75645529,  4.75645529,\n",
      "         4.75645529,  4.75645529,  4.75645529,  4.75645529,  4.75645529,\n",
      "         4.75645529,  4.75645529,  4.75645529,  4.75645529,  4.75645529]])]\n",
      "---------------------- h\n",
      "[array([[ 1.,  6.,  5.,  5.,  4.,  4.,  8.,  3.,  4.,  7.,  5.,  3.,  2.,\n",
      "         0.,  7.],\n",
      "       [ 2.,  3.,  2.,  6.,  9.,  5.,  2.,  3.,  6.,  8.,  5.,  7.,  5.,\n",
      "         5.,  0.],\n",
      "       [ 0., 10.,  9.,  3.,  5.,  2.,  8.,  7.,  3.,  2., 10.,  8.,  3.,\n",
      "         2.,  6.],\n",
      "       [ 8.,  5.,  4.,  9.,  5.,  1.,  0.,  6.,  6.,  2.,  2.,  7.,  2.,\n",
      "         3.,  8.]]), array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), array([[1.34479089e-03, 1.34479089e-03, 1.34479089e-03, 1.34479089e-03,\n",
      "        1.34479089e-03, 1.34479089e-03, 1.34479089e-03, 1.34479089e-03,\n",
      "        1.34479089e-03, 1.34479089e-03, 1.34479089e-03, 1.34479089e-03,\n",
      "        1.34479089e-03, 1.34479089e-03, 1.34479089e-03],\n",
      "       [8.85059690e-01, 8.85059690e-01, 8.85059690e-01, 8.85059690e-01,\n",
      "        8.85059690e-01, 8.85059690e-01, 8.85059690e-01, 8.85059690e-01,\n",
      "        8.85059690e-01, 8.85059690e-01, 8.85059690e-01, 8.85059690e-01,\n",
      "        8.85059690e-01, 8.85059690e-01, 8.85059690e-01],\n",
      "       [4.00155256e-02, 4.00155256e-02, 4.00155256e-02, 4.00155256e-02,\n",
      "        4.00155256e-02, 4.00155256e-02, 4.00155256e-02, 4.00155256e-02,\n",
      "        4.00155256e-02, 4.00155256e-02, 4.00155256e-02, 4.00155256e-02,\n",
      "        4.00155256e-02, 4.00155256e-02, 4.00155256e-02],\n",
      "       [7.27492335e-02, 7.27492335e-02, 7.27492335e-02, 7.27492335e-02,\n",
      "        7.27492335e-02, 7.27492335e-02, 7.27492335e-02, 7.27492335e-02,\n",
      "        7.27492335e-02, 7.27492335e-02, 7.27492335e-02, 7.27492335e-02,\n",
      "        7.27492335e-02, 7.27492335e-02, 7.27492335e-02],\n",
      "       [7.94630102e-04, 7.94630102e-04, 7.94630102e-04, 7.94630102e-04,\n",
      "        7.94630102e-04, 7.94630102e-04, 7.94630102e-04, 7.94630102e-04,\n",
      "        7.94630102e-04, 7.94630102e-04, 7.94630102e-04, 7.94630102e-04,\n",
      "        7.94630102e-04, 7.94630102e-04, 7.94630102e-04],\n",
      "       [3.61302276e-05, 3.61302276e-05, 3.61302276e-05, 3.61302276e-05,\n",
      "        3.61302276e-05, 3.61302276e-05, 3.61302276e-05, 3.61302276e-05,\n",
      "        3.61302276e-05, 3.61302276e-05, 3.61302276e-05, 3.61302276e-05,\n",
      "        3.61302276e-05, 3.61302276e-05, 3.61302276e-05]])]\n",
      "---------------------- gW\n",
      "[array([[ 0.02017186, 12.27589534, -2.39976712,  0.0912385 , -4.98808055,\n",
      "        -4.99945805]]), array([[ 3.50330066e-43],\n",
      "       [-8.55567194e-41],\n",
      "       [-3.45026657e-41],\n",
      "       [-4.89534354e-41]]), array([[0.]])]\n",
      "---------------------- gB\n",
      "[array([ 0.02017186, 12.27589534, -2.39976712,  0.0912385 , -4.98808055,\n",
      "       -4.99945805]), array([-1.69012813e-41]), array([0.])]\n",
      "---------------------- a\n",
      "[array([[0.]]), array([[ 50.41552972,  94.14844895,  77.45568438, 101.84767242,\n",
      "        102.55456701,  56.14639402,  71.06483783,  76.4802938 ,\n",
      "         85.05140473,  89.2164548 ,  87.90807789, 104.64285583,\n",
      "         54.46906784,  46.97835091,  83.48409021]]), array([[ 8.37327891,  8.37327891,  8.37327891,  8.37327891,  8.37327891,\n",
      "         8.37327891,  8.37327891,  8.37327891,  8.37327891,  8.37327891,\n",
      "         8.37327891,  8.37327891,  8.37327891,  8.37327891,  8.37327891],\n",
      "       [14.83818402, 14.83818402, 14.83818402, 14.83818402, 14.83818402,\n",
      "        14.83818402, 14.83818402, 14.83818402, 14.83818402, 14.83818402,\n",
      "        14.83818402, 14.83818402, 14.83818402, 14.83818402, 14.83818402],\n",
      "       [11.77114778, 11.77114778, 11.77114778, 11.77114778, 11.77114778,\n",
      "        11.77114778, 11.77114778, 11.77114778, 11.77114778, 11.77114778,\n",
      "        11.77114778, 11.77114778, 11.77114778, 11.77114778, 11.77114778],\n",
      "       [12.36391662, 12.36391662, 12.36391662, 12.36391662, 12.36391662,\n",
      "        12.36391662, 12.36391662, 12.36391662, 12.36391662, 12.36391662,\n",
      "        12.36391662, 12.36391662, 12.36391662, 12.36391662, 12.36391662],\n",
      "       [ 7.85717833,  7.85717833,  7.85717833,  7.85717833,  7.85717833,\n",
      "         7.85717833,  7.85717833,  7.85717833,  7.85717833,  7.85717833,\n",
      "         7.85717833,  7.85717833,  7.85717833,  7.85717833,  7.85717833],\n",
      "       [ 4.76645421,  4.76645421,  4.76645421,  4.76645421,  4.76645421,\n",
      "         4.76645421,  4.76645421,  4.76645421,  4.76645421,  4.76645421,\n",
      "         4.76645421,  4.76645421,  4.76645421,  4.76645421,  4.76645421]])]\n",
      "---------------------- h\n",
      "[array([[ 1.,  6.,  5.,  5.,  4.,  4.,  8.,  3.,  4.,  7.,  5.,  3.,  2.,\n",
      "         0.,  7.],\n",
      "       [ 2.,  3.,  2.,  6.,  9.,  5.,  2.,  3.,  6.,  8.,  5.,  7.,  5.,\n",
      "         5.,  0.],\n",
      "       [ 0., 10.,  9.,  3.,  5.,  2.,  8.,  7.,  3.,  2., 10.,  8.,  3.,\n",
      "         2.,  6.],\n",
      "       [ 8.,  5.,  4.,  9.,  5.,  1.,  0.,  6.,  6.,  2.,  2.,  7.,  2.,\n",
      "         3.,  8.]]), array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), array([[1.37397159e-03, 1.37397159e-03, 1.37397159e-03, 1.37397159e-03,\n",
      "        1.37397159e-03, 1.37397159e-03, 1.37397159e-03, 1.37397159e-03,\n",
      "        1.37397159e-03, 1.37397159e-03, 1.37397159e-03, 1.37397159e-03,\n",
      "        1.37397159e-03, 1.37397159e-03, 1.37397159e-03],\n",
      "       [8.82369259e-01, 8.82369259e-01, 8.82369259e-01, 8.82369259e-01,\n",
      "        8.82369259e-01, 8.82369259e-01, 8.82369259e-01, 8.82369259e-01,\n",
      "        8.82369259e-01, 8.82369259e-01, 8.82369259e-01, 8.82369259e-01,\n",
      "        8.82369259e-01, 8.82369259e-01, 8.82369259e-01],\n",
      "       [4.10821773e-02, 4.10821773e-02, 4.10821773e-02, 4.10821773e-02,\n",
      "        4.10821773e-02, 4.10821773e-02, 4.10821773e-02, 4.10821773e-02,\n",
      "        4.10821773e-02, 4.10821773e-02, 4.10821773e-02, 4.10821773e-02,\n",
      "        4.10821773e-02, 4.10821773e-02, 4.10821773e-02],\n",
      "       [7.43172599e-02, 7.43172599e-02, 7.43172599e-02, 7.43172599e-02,\n",
      "        7.43172599e-02, 7.43172599e-02, 7.43172599e-02, 7.43172599e-02,\n",
      "        7.43172599e-02, 7.43172599e-02, 7.43172599e-02, 7.43172599e-02,\n",
      "        7.43172599e-02, 7.43172599e-02, 7.43172599e-02],\n",
      "       [8.20045821e-04, 8.20045821e-04, 8.20045821e-04, 8.20045821e-04,\n",
      "        8.20045821e-04, 8.20045821e-04, 8.20045821e-04, 8.20045821e-04,\n",
      "        8.20045821e-04, 8.20045821e-04, 8.20045821e-04, 8.20045821e-04,\n",
      "        8.20045821e-04, 8.20045821e-04, 8.20045821e-04],\n",
      "       [3.72866775e-05, 3.72866775e-05, 3.72866775e-05, 3.72866775e-05,\n",
      "        3.72866775e-05, 3.72866775e-05, 3.72866775e-05, 3.72866775e-05,\n",
      "        3.72866775e-05, 3.72866775e-05, 3.72866775e-05, 3.72866775e-05,\n",
      "        3.72866775e-05, 3.72866775e-05, 3.72866775e-05]])]\n",
      "---------------------- gW\n",
      "[array([[ 0.02060957, 12.23553888, -2.38376734,  0.1147589 , -4.98769931,\n",
      "        -4.9994407 ]]), array([[ 3.49014051e-43],\n",
      "       [-8.73192726e-41],\n",
      "       [-3.52066352e-41],\n",
      "       [-5.00199100e-41]]), array([[0.]])]\n",
      "---------------------- gB\n",
      "[array([ 0.02060957, 12.23553888, -2.38376734,  0.1147589 , -4.98769931,\n",
      "       -4.9994407 ]), array([-1.7254581e-41]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05],\n",
       "       [1.40359059e-03, 8.79636645e-01, 4.21700936e-02, 7.59050391e-02,\n",
       "        8.46157052e-04, 3.84748331e-05]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[ 1.,  2.,  0.,  8.],\n",
    " [ 6.,  3., 10.,  5.],\n",
    " [ 5.,  2.,  9.,  4.],\n",
    " [ 5.,  6.,  3.,  9.],\n",
    " [ 4.,  9.,  5.,  5.],\n",
    " [ 4.,  5.,  2.,  1.],\n",
    " [ 8.,  2.,  8.,  0.],\n",
    " [ 3.,  3.,  7.,  6.],\n",
    " [ 4.,  6.,  3.,  6.],\n",
    " [ 7.,  8.,  2.,  2.],\n",
    " [ 5.,  5., 10.,  2.],\n",
    " [ 3.,  7.,  8.,  7.],\n",
    " [ 2.,  5.,  3.,  2.],\n",
    " [ 0.,  5.,  2.,  3.],\n",
    " [ 7.,  0.,  6.,  8.]])\n",
    "y = np.array([3, 6, 5, 6, 6, 3, 4, 5, 5, 5, 6, 6, 3, 2, 5])\n",
    "model = FNNClassifier(1, 2, activation = 'tanh', optimizer = 'normal', num_epochs = 2)\n",
    "model.fit(X, y)\n",
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "    'method' : 'random',\n",
    "    'metric' : {\n",
    "        'name' : 'accuracy',\n",
    "        'goal' : 'maximize'\n",
    "    },\n",
    "    'parameters' : {\n",
    "        'N' : [32, 64, 128],\n",
    "        'L' : [3, 4, 5],\n",
    "        'activation' : ['sigmoid', 'tanh', 'ReLU'],\n",
    "        'optimizer' : ['sgd', 'momentum', 'nesterov', 'rmsprop', 'adam', 'nadam'],\n",
    "        'weight_decay' : [0, 0.0005, 0.5],\n",
    "        'batch_size' : [16, 32, 64],\n",
    "        'num_epochs' : [5, 10],\n",
    "        'learning_rate' : [0.001, 0.0001],\n",
    "        'weight_init' : ['random', 'Xavier']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity = 'sweep', project = 'cs6910a12021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    def_params = {\n",
    "        'N' : 32,\n",
    "        'L' : 4,\n",
    "        'activation' : 'ReLU',\n",
    "        'optimizer' : 'adam',\n",
    "        'weight_decay' : 0.0005,\n",
    "        'batch_size' : 32,\n",
    "        'num_epochs' : 5,\n",
    "        'learning_rate' : 0.001,\n",
    "        'weight_init' : 'random'\n",
    "    }\n",
    "    wandb.init(config = def_params)\n",
    "    config = wandb.config\n",
    "    model = FFNClassifier(**config)\n",
    "    model.fit(X_train, Y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
