{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers, applications\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from matplotlib import image\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 10 classes.\n",
      "Found 999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../../nature_12K/inaturalist_12K\"\n",
    "train_path = dataset_path + \"/train\"\n",
    "test_path = dataset_path + \"/val\"\n",
    "max_shape = (256, 256, 3)\n",
    "\n",
    "data_train = ImageDataGenerator(validation_split = 0.1)#, rescale = 1. / 255)\n",
    "\n",
    "data_test = ImageDataGenerator()#rescale = 1. / 255)\n",
    "\n",
    "train_generator = data_train.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(max_shape[0], max_shape[1]),\n",
    "        class_mode='categorical',\n",
    "        subset = 'training')\n",
    "\n",
    "validation_generator = data_train.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(max_shape[0], max_shape[1]),\n",
    "        class_mode='categorical',\n",
    "        subset = 'validation')\n",
    "\n",
    "test_generator = data_test.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(max_shape[0], max_shape[1]),\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuneCNN(model_name, retrain):\n",
    "    base_model = eval('applications' + model_name + '(input_shape=max_shape, include_top=False, weights=\\'imagenet\\')')\n",
    "    base_model.trainable = True\n",
    "    non_train = int((1 - retrain) * len(base_model.layers))\n",
    "    for layer in base_model.layers[:non_train]:\n",
    "        layer.trainable = False\n",
    "    # base_model.summary()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=max_shape)\n",
    "    #data_augmentation = tf.keras.Sequential([ \n",
    "    #layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    #layers.experimental.preprocessing.RandomRotation(0.2)])\n",
    "    #x = data_augmentation(inputs)\n",
    "    #x = preprocess_input(x)\n",
    "    x = inputs\n",
    "    x = base_model(x)\n",
    "    global_average_layer = layers.GlobalAveragePooling2D()\n",
    "    x = global_average_layer(x)\n",
    "    prediction_layer = layers.Dense(10)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    # model.summary()\n",
    "    # len(base_model.layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (299, 299, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9d4e1d04d4c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mretrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInceptionResNetV2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnon_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mretrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py\u001b[0m in \u001b[0;36mInceptionResNetV2\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m   \u001b[1;31m# Determine proper input shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m   input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m       \u001b[0mdefault_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         raise ValueError('When setting `include_top=True` '\n\u001b[0m\u001b[0;32m    344\u001b[0m                          \u001b[1;34m'and loading `imagenet` weights, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                          '`input_shape` should be ' + str(default_shape) + '.')\n",
      "\u001b[1;31mValueError\u001b[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (299, 299, 3)."
     ]
    }
   ],
   "source": [
    "# Change here to change the pre-trained model\n",
    "\n",
    "retrain = 0.2\n",
    "base_model = applications.InceptionResNetV2(input_shape=max_shape, include_top=False, weights='imagenet')\n",
    "base_model.trainable = True\n",
    "non_train = int((1 - retrain) * len(base_model.layers))\n",
    "for layer in base_model.layers[:non_train]:\n",
    "    layer.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 6, 6, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                15370     \n",
      "=================================================================\n",
      "Total params: 54,352,106\n",
      "Trainable params: 23,028,586\n",
      "Non-trainable params: 31,323,520\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=max_shape)\n",
    "#data_augmentation = tf.keras.Sequential([ \n",
    "                            #layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "                            #layers.experimental.preprocessing.RandomRotation(0.2)])\n",
    "#x = data_augmentation(inputs)\n",
    "#x = preprocess_input(x)\n",
    "x = inputs\n",
    "x = base_model(x)\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "x = global_average_layer(x)\n",
    "prediction_layer = layers.Dense(10)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - ETA: 0s - loss: 2.3733 - accuracy: 0.1457"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, validation_data=validation_generator)#, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          loss_fn,\n",
    "          ):\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics = ['accuracy'])\n",
    "    model.fit(train_generator, epochs=10, validation_data=validation_generator, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "        'name': 'accuracy',\n",
    "        'goal': 'maximize'\n",
    "    }, 'parameters' : {\n",
    "            'model' : {\n",
    "                'values' : ['InceptionV3', 'InceptionResNetV2', 'ResNet50', 'Xception', 'NASNetLarge']\n",
    "            }\n",
    "            'retrain' : {\n",
    "                'values' : [0.1, 0.15, 0.2]\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity = '0x2e4', project = 'cs6910-a2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    default_config = {\n",
    "              'model' : 'InceptionResNetV2'\n",
    "                'retrain' : 0.1\n",
    "           }\n",
    "\n",
    "    run = wandb.init(project='cs6910-a2', config=default_config)\n",
    "    config = wandb.config\n",
    "\n",
    "    # initialize model\n",
    "    model = finetuneCNN(model_name = config.model, retrain = config.retrain)\n",
    "\n",
    "    # Instantiate an optimizer to train the model.\n",
    "    optimizer = tf.keras.optimizers.Nadam()\n",
    "    # Instantiate a loss function.\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    train(model,\n",
    "      optimizer,\n",
    "      loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
