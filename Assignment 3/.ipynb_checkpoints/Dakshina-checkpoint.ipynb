{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up input flows\n",
    "\n",
    "dataset_path = \"../../dakshina_dataset_v1.0/ta/lexicons\"\n",
    "train_path = dataset_path + \"/ta.translit.sampled.train.tsv\"\n",
    "test_path = dataset_path + \"/ta.translit.sampled.test.tsv\"\n",
    "\n",
    "train_data = ''.join([each.decode('utf-8') for each in open(train_path, 'rb')]).split()\n",
    "y_train, X_train, z_train = train_data[::3], train_data[1::3], [int(each) for each in train_data[2::3]]\n",
    "\n",
    "test_data = ''.join([each.decode('utf-8') for each in open(test_path, 'rb')]).split()\n",
    "y_test, X_test, z_test = test_data[::3], test_data[1::3], [int(each) for each in test_data[2::3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the vocabulary\n",
    "\n",
    "input_vocab, output_vocab = set(), set()\n",
    "\n",
    "max_input_len, max_output_len = 0, 0\n",
    "\n",
    "for each in X_train:\n",
    "    for every in each:\n",
    "        input_vocab.add(every)\n",
    "    max_input_len = max(max_input_len, len(each))\n",
    "for each in X_test:\n",
    "    for every in each:\n",
    "        input_vocab.add(every)\n",
    "    max_input_len = max(max_input_len, len(each))\n",
    "\n",
    "for each in y_train:\n",
    "    for every in each:\n",
    "        output_vocab.add(every)\n",
    "    max_output_len = max(max_output_len, len(each))\n",
    "for each in y_test:\n",
    "    for every in each:\n",
    "        output_vocab.add(every)\n",
    "    max_output_len = max(max_output_len, len(each))\n",
    "        \n",
    "input_vocab.add(\" \")\n",
    "output_vocab.add(\" \")\n",
    "\n",
    "input_vocab = sorted(list(input_vocab))\n",
    "output_vocab = sorted(list(output_vocab))\n",
    "input_v_len = len(input_vocab)\n",
    "output_v_len = len(output_vocab)\n",
    "\n",
    "input_inv = dict([(char, i) for i, char in enumerate(input_vocab)])\n",
    "output_inv = dict([(char, i) for i, char in enumerate(output_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(X, y):\n",
    "    \n",
    "    encoder_input_data = np.zeros((len(X), max_input_len, input_v_len), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros((len(X), max_output_len, output_v_len), dtype=\"float32\")\n",
    "    decoder_target_data = np.zeros((len(X), max_output_len, output_v_len), dtype=\"float32\")\n",
    "\n",
    "    for i, (a, b) in enumerate(zip(X, y)):\n",
    "        for t, char in enumerate(a):\n",
    "            encoder_input_data[i, t, input_inv[char]] = 1.0\n",
    "        encoder_input_data[i, t + 1 :, output_inv[\" \"]] = 1.0\n",
    "        for t, char in enumerate(b):\n",
    "            decoder_input_data[i, t, output_inv[char]] = 1.0\n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t - 1, output_inv[char]] = 1.0\n",
    "        decoder_input_data[i, t + 1 :, output_inv[\" \"]] = 1.0\n",
    "        decoder_target_data[i, t:, output_inv[\" \"]] = 1.0\n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRNN(latent_dim, embed_dim, dropout, cell_type):\n",
    "    encoder_inputs = tf.keras.Input(shape=(None, input_v_len))\n",
    "    encoder_embedded = layers.Embedding(input_dim=input_v_len, output_dim=embed_dim)(encoder_input)\n",
    "    \n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder = layers.LSTM(latent_dim, return_state=True)\n",
    "         _, state_h, state_C = encoder(encoder_embedded)\n",
    "        encoder_states = [state_h, state_c]\n",
    "    else:\n",
    "        if cell_type == 'SimpleRNN':\n",
    "            encoder = layers.SimpleRNN(latent_dim, return_state=True)\n",
    "        else:\n",
    "            encoder = layers.GRU(latent_dim, return_state=True)\n",
    "        _, state_h = encoder(encoder_embedded)\n",
    "        encoder_states = [state_h]\n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None, output_v_len))\n",
    "    decoder_embedded = layers.Embedding(input_dim=output_v_len, output_dim=embed_dim)(decoder_input)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        decoder = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_RNN(decoder_embedded, initial_state=encoder_states)\n",
    "    else:\n",
    "        if cell_type == 'SimpleRNN':\n",
    "            decoder = layers.SimpleRNN(latent_dim, return_sequences=True, return_state=True)\n",
    "        else:\n",
    "            decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _ = decoder_RNN(decoder_embedded, initial_state=encoder_states)\n",
    "    \n",
    "    decoder_dense = layers.Dense(output_v_len, activation=\"softmax\")\n",
    "    decoder_dense_drop = layers.Dropout(dropout)(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_dense_drop)\n",
    "\n",
    "    model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myRNN(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 47)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn (SimpleRNN)          [(None, 128), (None, 19968       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)        [(None, None, 128),  22528       input_2[0][0]                    \n",
      "                                                                 simple_rnn[0][1]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 47)     6063        simple_rnn_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 48,559\n",
      "Trainable params: 48,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size=64, epochs=1):\n",
    "    model.compile(optimizer=\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    aa, bb, cc = onehot(X_train, y_train)\n",
    "    model.fit([aa, bb], cc, batch_size=batch_size, epochs=epochs, validation_split=0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 37s 38ms/step - loss: 0.7546 - accuracy: 0.7939 - val_loss: 0.6277 - val_accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(model):\n",
    "    latent_dim = model.layers[3].units\n",
    "    \n",
    "    encoder_inputs = model.input[0]\n",
    "    _, state_h_enc = model.layers[2].output\n",
    "    encoder_states = [state_h_enc]\n",
    "    encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_inputs = model.input[1]\n",
    "    decoder_state_input_h = tf.keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "    decoder_states_inputs = [decoder_state_input_h]\n",
    "    decoder_RNN = model.layers[3]\n",
    "    decoder_outputs, state_h_dec = decoder_RNN(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h_dec]\n",
    "    decoder_dense = model.layers[4]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 27)]        0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       [(None, 128), (None, 128) 19968     \n",
      "=================================================================\n",
      "Total params: 19,968\n",
      "Trainable params: 19,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 47)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)        [(None, None, 128),  22528       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 47)     6063        simple_rnn_1[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 28,591\n",
      "Trainable params: 28,591\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ok, okok = decompose(model)\n",
    "ok.summary()\n",
    "okok.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 27) (None, 128)\n",
      "(None, None, 47) (None, 128) (None, None, 47) (None, 128)\n"
     ]
    }
   ],
   "source": [
    "print(ok.input.shape, ok.output.shape)\n",
    "print(okok.input[0].shape, okok.input[1].shape, okok.output[0].shape, okok.output[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the sequence\n",
    "\n",
    "reverse_inp = dict((i, char) for char, i in input_inv.items())\n",
    "reverse_out = dict((i, char) for char, i in output_inv.items())\n",
    "\n",
    "def decode_sequence(model, input_seq):\n",
    "    \n",
    "    encoder_model, decoder_model = decompose(model)\n",
    "    \n",
    "    enc_states = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, output_v_len))\n",
    "    target_seq[0, 0, output_inv[\" \"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    final_ans = \"\"\n",
    "    while not stop_condition:\n",
    "        print(len(final_ans))\n",
    "        output_chars, h = decoder_model.predict([target_seq] + [enc_states])\n",
    "\n",
    "        sampled_char_index = np.argmax(output_chars[0, -1, :])\n",
    "        sampled_char = reverse_out[sampled_char_index]\n",
    "        final_ans += sampled_char\n",
    "\n",
    "        if sampled_char == \" \" or len(final_ans) > max_output_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, output_v_len))\n",
    "        target_seq[0, 0, sampled_char_index] = 1.0\n",
    "\n",
    "        enc_states = [h]\n",
    "    return final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E19C4C18B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E1B29B9B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E1B29B9B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'யைப்பட்டிர்டுட்டு '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "aa, bb, cc = onehot(X_train, y_train)\n",
    "print(bb[n:n+1])\n",
    "decode_sequence(model, aa[n:n+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.array([[1, 2], [1, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "        'name': 'accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'model': {\n",
    "            'values': [\n",
    "                'InceptionV3', 'InceptionResNetV2', 'ResNet50', 'Xception',\n",
    "                'NASNetLarge'\n",
    "            ]\n",
    "        },\n",
    "        'retrain': {\n",
    "            'values': [0.1, 0.15, 0.2]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
