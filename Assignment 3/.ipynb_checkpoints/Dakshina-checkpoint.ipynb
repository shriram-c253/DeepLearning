{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up input flows\n",
    "\n",
    "dataset_path = \"../../dakshina_dataset_v1.0/ta/lexicons\"\n",
    "train_path = dataset_path + \"/ta.translit.sampled.train.tsv\"\n",
    "test_path = dataset_path + \"/ta.translit.sampled.test.tsv\"\n",
    "\n",
    "train_data = ''.join([each.decode('utf-8') for each in open(train_path, 'rb')]).split()\n",
    "y_train, X_train, z_train = train_data[::3], train_data[1::3], [int(each) for each in train_data[2::3]]\n",
    "\n",
    "test_data = ''.join([each.decode('utf-8') for each in open(test_path, 'rb')]).split()\n",
    "y_test, X_test, z_test = test_data[::3], test_data[1::3], [int(each) for each in test_data[2::3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the vocabulary\n",
    "\n",
    "input_vocab, output_vocab = set(), set()\n",
    "\n",
    "max_input_len, max_output_len = 0, 0\n",
    "\n",
    "for each in X_train:\n",
    "    for every in each:\n",
    "        input_vocab.add(every)\n",
    "    max_input_len = max(max_input_len, len(each))\n",
    "for each in X_test:\n",
    "    for every in each:\n",
    "        input_vocab.add(every)\n",
    "    max_input_len = max(max_input_len, len(each))\n",
    "\n",
    "for each in y_train:\n",
    "    for every in each:\n",
    "        output_vocab.add(every)\n",
    "    max_output_len = max(max_output_len, len(each))\n",
    "for each in y_test:\n",
    "    for every in each:\n",
    "        output_vocab.add(every)\n",
    "    max_output_len = max(max_output_len, len(each))\n",
    "        \n",
    "input_vocab.add(\" \")\n",
    "output_vocab.add(\" \")\n",
    "\n",
    "input_vocab = sorted(list(input_vocab))\n",
    "output_vocab = sorted(list(output_vocab))\n",
    "input_v_len = len(input_vocab)\n",
    "output_v_len = len(output_vocab)\n",
    "\n",
    "input_inv = dict([(char, i) for i, char in enumerate(input_vocab)])\n",
    "output_inv = dict([(char, i) for i, char in enumerate(output_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(X, y):\n",
    "    \n",
    "    encoder_input_data = np.zeros((len(X), max_input_len, input_v_len), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros((len(X), max_output_len, output_v_len), dtype=\"float32\")\n",
    "    decoder_target_data = np.zeros((len(X), max_output_len, output_v_len), dtype=\"float32\")\n",
    "\n",
    "    for i, (a, b) in enumerate(zip(X, y)):\n",
    "        for t, char in enumerate(a):\n",
    "            encoder_input_data[i, t, input_inv[char]] = 1.0\n",
    "        encoder_input_data[i, t + 1 :, output_inv[\" \"]] = 1.0\n",
    "        for t, char in enumerate(b):\n",
    "            decoder_input_data[i, t, output_inv[char]] = 1.0\n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t - 1, output_inv[char]] = 1.0\n",
    "        decoder_input_data[i, t + 1 :, output_inv[\" \"]] = 1.0\n",
    "        decoder_target_data[i, t:, output_inv[\" \"]] = 1.0\n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRNN(latent_dim, num_encoders = 1, num_decoders = 1, embed_dim = 1000, dropout = 0.0, cell_type = 'GRU'):\n",
    "    encoder_inputs = tf.keras.Input(shape=(None, input_v_len))\n",
    "    #encoder_inputs = layers.Embedding(input_dim=input_v_len, output_dim=embed_dim)(encoder_inputs)\n",
    "    \n",
    "    encoder_inp = encoder_inputs\n",
    "    \n",
    "    for ii in range(num_encoders):\n",
    "        if cell_type == 'LSTM':\n",
    "            encoder = layers.LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "            encoder_inp, state_h, state_C = encoder(encoder_inp)\n",
    "            encoder_states = [state_h, state_c]\n",
    "        else:\n",
    "            if cell_type == 'RNN':\n",
    "                encoder = layers.SimpleRNN(latent_dim, return_state=True, return_sequences=True)\n",
    "            else:\n",
    "                encoder = layers.GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "            encoder_inp, state_h = encoder(encoder_inp)\n",
    "            encoder_states = [state_h]\n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None, output_v_len))\n",
    "    #decoder_inputs = layers.Embedding(input_dim=output_v_len, output_dim=embed_dim)(decoder_inputs)\n",
    "    \n",
    "    decoder_out = decoder_inputs\n",
    "    temp_states = encoder_states\n",
    "    \n",
    "    for ii in range(num_decoders):\n",
    "        if cell_type == 'LSTM':\n",
    "            decoder = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "            decoder_out, temp_state_h, temp_state_c = decoder_RNN(decoder_out, initial_state=temp_states)\n",
    "            temp_states = [temp_state_h, temp_state_c]\n",
    "        else:\n",
    "            if cell_type == 'RNN':\n",
    "                decoder = layers.SimpleRNN(latent_dim, return_sequences=True, return_state=True)\n",
    "            else:\n",
    "                decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
    "            decoder_out, temp_state_h = decoder(decoder_out, initial_state=temp_states)\n",
    "            temp_states = [temp_state_h]\n",
    "    \n",
    "    decoder_outputs = decoder_out\n",
    "    decoder_dense = layers.Dense(output_v_len, activation=\"softmax\")\n",
    "    decoder_dense_drop = layers.Dropout(dropout)(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_dense_drop)\n",
    "\n",
    "    model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size=64, epochs=25):\n",
    "    model.compile(optimizer=\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    aa, bb, cc = onehot(X_train, y_train)\n",
    "    model.fit([aa, bb], cc, batch_size=batch_size, epochs=epochs, validation_split=0.1,)#callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(model_org):\n",
    "    model = models.clone_model(model_org)\n",
    "    latent_dim = model.layers[1].units\n",
    "    dropout = 0.3\n",
    "    num_encoders = 3\n",
    "    num_decoders = 3\n",
    "    \n",
    "    encoder_inputs = model.input[0]\n",
    "    _, state_h_enc = model.layers[num_encoders + 1].output\n",
    "    encoder_states = [state_h_enc]\n",
    "    encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_inputs = model.input[1]\n",
    "    decoder_state_input_h = tf.keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "    decoder_states_inputs = [decoder_state_input_h]\n",
    "    \n",
    "    decoder_out = decoder_inputs\n",
    "    temp_states = decoder_states_inputs\n",
    "    \n",
    "    for ii in range(num_decoders):\n",
    "        decoder = model.layers[num_encoders + 2 + ii]\n",
    "        decoder_out, temp_state_h = decoder(decoder_out, initial_state=temp_states)\n",
    "        temp_states = [temp_state_h]\n",
    "    \n",
    "    decoder_outputs, decoder_states = decoder_out, temp_states\n",
    "    decoder_dense = model.layers[num_encoders + num_decoders + 3]\n",
    "    decoder_dense_drop = model.layers[num_encoders + num_decoders + 2](decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_dense_drop)\n",
    "    \n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the sequence\n",
    "\n",
    "reverse_inp = dict((i, char) for char, i in input_inv.items())\n",
    "reverse_out = dict((i, char) for char, i in output_inv.items())\n",
    "\n",
    "def decode_sequence(model, input_seq):\n",
    "    \n",
    "    encoder_model, decoder_model = decompose(model)\n",
    "    \n",
    "    enc_states = encoder_model(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, output_v_len))\n",
    "    target_seq[0, 0, output_inv[\" \"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    final_ans = \"\"\n",
    "    while not stop_condition:\n",
    "        output_chars, h = decoder_model([target_seq] + [enc_states])\n",
    "\n",
    "        sampled_char_index = np.argmax(output_chars[0, -1, :])\n",
    "        sampled_char = reverse_out[sampled_char_index]\n",
    "        final_ans += sampled_char\n",
    "\n",
    "        if sampled_char == \" \" or len(final_ans) > max_output_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, output_v_len))\n",
    "        target_seq[0, 0, sampled_char_index] = 1.0\n",
    "\n",
    "        enc_states = [h]\n",
    "    return final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'hidden_layer_size': {\n",
    "            'values': [\n",
    "                16, 64, 128, 256\n",
    "            ],\n",
    "        },\n",
    "        'num_encoders': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'num_decoders': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.0, 0.2, 0.3]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['RNN', 'LSTM', 'GRU']\n",
    "        },\n",
    "        'num_epochs': {\n",
    "            'values': [30, 45, 60]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sweep_id = wandb.sweep(sweep_config, entity = '0x2e4', project = 'cs6910-a3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run():\n",
    "    default_config = {'hidden_layer_size': 16, 'num_encoders': 1, 'num_decoders': 1, 'dropout': 0.0, 'cell_type': 'RNN', 'num_epochs': 30}\n",
    "\n",
    "    run = wandb.init(project='cs6910-a3', config=default_config)\n",
    "    config = wandb.config\n",
    "\n",
    "    model = myRNN(latent_dim=config.hidden_layer_size, num_encoders = config.num_encoders, num_decoders = config.num_decoders, dropout = config.dropout, cell_type = config.cell_type)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Nadam()\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    train(model, epochs=config.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.agent(sweep_id, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "960/960 [==============================] - 47s 34ms/step - loss: 1.0038 - accuracy: 0.7458 - val_loss: 0.5887 - val_accuracy: 0.8269\n",
      "Epoch 2/60\n",
      "960/960 [==============================] - 31s 32ms/step - loss: 0.5147 - accuracy: 0.8474 - val_loss: 0.3790 - val_accuracy: 0.8878\n",
      "Epoch 3/60\n",
      "960/960 [==============================] - 32s 33ms/step - loss: 0.2883 - accuracy: 0.9135 - val_loss: 0.2172 - val_accuracy: 0.9331\n",
      "Epoch 4/60\n",
      "960/960 [==============================] - 33s 34ms/step - loss: 0.1473 - accuracy: 0.9577 - val_loss: 0.1595 - val_accuracy: 0.9525\n",
      "Epoch 5/60\n",
      "960/960 [==============================] - 34s 35ms/step - loss: 0.0862 - accuracy: 0.9762 - val_loss: 0.1105 - val_accuracy: 0.9676\n",
      "Epoch 6/60\n",
      "960/960 [==============================] - 35s 36ms/step - loss: 0.0554 - accuracy: 0.9848 - val_loss: 0.1021 - val_accuracy: 0.9694\n",
      "Epoch 7/60\n",
      "960/960 [==============================] - 36s 37ms/step - loss: 0.0393 - accuracy: 0.9894 - val_loss: 0.0882 - val_accuracy: 0.9737\n",
      "Epoch 8/60\n",
      "960/960 [==============================] - 37s 38ms/step - loss: 0.0296 - accuracy: 0.9918 - val_loss: 0.0894 - val_accuracy: 0.9729\n",
      "Epoch 9/60\n",
      "960/960 [==============================] - 39s 41ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0783 - val_accuracy: 0.9771\n",
      "Epoch 10/60\n",
      "960/960 [==============================] - 40s 41ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.0881 - val_accuracy: 0.9752\n",
      "Epoch 11/60\n",
      "960/960 [==============================] - 41s 43ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0796 - val_accuracy: 0.9777\n",
      "Epoch 12/60\n",
      "960/960 [==============================] - 42s 44ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0650 - val_accuracy: 0.9818\n",
      "Epoch 13/60\n",
      "960/960 [==============================] - 43s 45ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0609 - val_accuracy: 0.9828\n",
      "Epoch 14/60\n",
      "960/960 [==============================] - 44s 46ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0599 - val_accuracy: 0.9834\n",
      "Epoch 15/60\n",
      "960/960 [==============================] - 45s 47ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0629 - val_accuracy: 0.9825\n",
      "Epoch 16/60\n",
      "960/960 [==============================] - 45s 47ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0680 - val_accuracy: 0.9810\n",
      "Epoch 17/60\n",
      "960/960 [==============================] - 44s 46ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0500 - val_accuracy: 0.9859\n",
      "Epoch 18/60\n",
      "960/960 [==============================] - 45s 47ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0583 - val_accuracy: 0.9831\n",
      "Epoch 19/60\n",
      "960/960 [==============================] - 45s 47ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0495 - val_accuracy: 0.9861\n",
      "Epoch 20/60\n",
      "960/960 [==============================] - 45s 47ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0552 - val_accuracy: 0.9857\n",
      "Epoch 21/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0534 - val_accuracy: 0.9857\n",
      "Epoch 22/60\n",
      "960/960 [==============================] - 48s 50ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0679 - val_accuracy: 0.9827\n",
      "Epoch 23/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0448 - val_accuracy: 0.9884\n",
      "Epoch 24/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0459 - val_accuracy: 0.9880\n",
      "Epoch 25/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
      "Epoch 26/60\n",
      "960/960 [==============================] - 48s 50ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0481 - val_accuracy: 0.9874\n",
      "Epoch 27/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0501 - val_accuracy: 0.9867\n",
      "Epoch 28/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0515 - val_accuracy: 0.9868\n",
      "Epoch 29/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0459 - val_accuracy: 0.9883\n",
      "Epoch 30/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0447 - val_accuracy: 0.9880\n",
      "Epoch 31/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0622 - val_accuracy: 0.9857\n",
      "Epoch 32/60\n",
      "960/960 [==============================] - 46s 48ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0515 - val_accuracy: 0.9874\n",
      "Epoch 33/60\n",
      "960/960 [==============================] - 46s 48ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0636 - val_accuracy: 0.9844\n",
      "Epoch 34/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0477 - val_accuracy: 0.9875\n",
      "Epoch 35/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0469 - val_accuracy: 0.9880\n",
      "Epoch 36/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0421 - val_accuracy: 0.9891\n",
      "Epoch 37/60\n",
      "960/960 [==============================] - 46s 48ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0520 - val_accuracy: 0.9875\n",
      "Epoch 38/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0396 - val_accuracy: 0.9897\n",
      "Epoch 39/60\n",
      "960/960 [==============================] - 50s 52ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0744 - val_accuracy: 0.9814\n",
      "Epoch 40/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0342 - val_accuracy: 0.9908\n",
      "Epoch 41/60\n",
      "960/960 [==============================] - 48s 51ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0408 - val_accuracy: 0.9893\n",
      "Epoch 42/60\n",
      "960/960 [==============================] - 48s 50ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0381 - val_accuracy: 0.9905\n",
      "Epoch 43/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0580 - val_accuracy: 0.9863\n",
      "Epoch 44/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0438 - val_accuracy: 0.9885\n",
      "Epoch 45/60\n",
      "960/960 [==============================] - 46s 48ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0437 - val_accuracy: 0.9885\n",
      "Epoch 46/60\n",
      "960/960 [==============================] - 48s 50ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0469 - val_accuracy: 0.9884\n",
      "Epoch 47/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
      "Epoch 48/60\n",
      "960/960 [==============================] - 47s 49ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0393 - val_accuracy: 0.9901\n",
      "Epoch 49/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0376 - val_accuracy: 0.9903\n",
      "Epoch 50/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0251 - val_accuracy: 0.9934\n",
      "Epoch 51/60\n",
      "960/960 [==============================] - 51s 53ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0270 - val_accuracy: 0.9931\n",
      "Epoch 52/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0334 - val_accuracy: 0.9913\n",
      "Epoch 53/60\n",
      "960/960 [==============================] - 51s 53ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0257 - val_accuracy: 0.9937\n",
      "Epoch 54/60\n",
      "960/960 [==============================] - 52s 54ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0306 - val_accuracy: 0.9922\n",
      "Epoch 55/60\n",
      "960/960 [==============================] - 50s 52ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0361 - val_accuracy: 0.9910\n",
      "Epoch 56/60\n",
      "960/960 [==============================] - 50s 52ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0447 - val_accuracy: 0.9895\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 46s 48ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0332 - val_accuracy: 0.9916\n",
      "Epoch 58/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0358 - val_accuracy: 0.9914\n",
      "Epoch 59/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0254 - val_accuracy: 0.9934\n",
      "Epoch 60/60\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 8.1816e-04 - accuracy: 0.9998 - val_loss: 0.0317 - val_accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "best_model = myRNN(cell_type = 'GRU',\n",
    "                  latent_dim = 128,\n",
    "                   dropout = 0.3,\n",
    "                   num_encoders = 3,\n",
    "                   num_decoders = 3\n",
    "                  )\n",
    "optimizer = tf.keras.optimizers.Nadam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train(best_model, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       [(None, None, 128),  60288       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, None, 128),  99072       gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 47)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, None, 128),  99072       gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     [(None, None, 128),  67968       input_2[0][0]                    \n",
      "                                                                 gru_2[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     [(None, None, 128),  99072       gru_3[0][0]                      \n",
      "                                                                 gru_3[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     [(None, None, 128),  99072       gru_4[0][0]                      \n",
      "                                                                 gru_4[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 128)    0           gru_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 47)     6063        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 530,607\n",
      "Trainable params: 530,607\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 27)]        0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    [(None, None, 128), (None 60288     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  [(None, None, 128), (None 99072     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  [(None, None, 128), (None 99072     \n",
      "=================================================================\n",
      "Total params: 258,432\n",
      "Trainable params: 258,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 47)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     [(None, None, 128),  67968       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     [(None, None, 128),  99072       gru_3[1][0]                      \n",
      "                                                                 gru_3[1][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     [(None, None, 128),  99072       gru_4[1][0]                      \n",
      "                                                                 gru_4[1][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 128)    0           gru_5[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 47)     6063        dropout[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 272,175\n",
      "Trainable params: 272,175\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()\n",
    "em, dm = decompose(best_model)\n",
    "em.summary()\n",
    "dm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "for ii in range(test_in.shape[0]):\n",
    "    res = decode_sequence(best_model, test_in[ii: ii + 1])\n",
    "    #print(res, y_test[ii])\n",
    "    if res == y_test[ii]:\n",
    "        cnt += 1\n",
    "        \n",
    "print(cnt / test_in.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in, test_out, _ = onehot(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6864, 30, 27)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=[50, 100])\n",
    "all_classes = list(test_generator.class_indices.keys())\n",
    "\n",
    "ax = pyplot.subplot(11, 3, 1)\n",
    "ax1 = pyplot.subplot(11, 3, 2)\n",
    "ax2 = pyplot.subplot(11, 3, 3)\n",
    "ax.axis('off')\n",
    "ax.text(0.3, 0.5, \"Sample Image\", fontsize=70)\n",
    "ax1.axis('off')\n",
    "ax1.text(0.3, 0.5, \"Prediction\", fontsize=70)\n",
    "ax2.axis('off')\n",
    "ax2.text(0.3, 0.5, \"True Class\", fontsize=70)\n",
    "\n",
    "for some in os.listdir(test_path):\n",
    "    idx = test_generator.class_indices[some]\n",
    "    new_path = test_path + \"/\" + some\n",
    "    img_path = new_path + \"/\" + os.listdir(new_path)[0]\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path,\n",
    "                                                target_size=(max_shape[0],\n",
    "                                                             max_shape[1]))\n",
    "    img_np = np.asarray(img)\n",
    "    ax = pyplot.subplot(11, 3, 3 * idx + 4)\n",
    "    ax1 = pyplot.subplot(11, 3, 3 * idx + 5)\n",
    "    ax2 = pyplot.subplot(11, 3, 3 * idx + 6)\n",
    "    ax.imshow(img_np)\n",
    "    ax1.axis('off')\n",
    "    ax1.text(0.3, 0.5, all_classes[y_pred[200 * idx]], fontsize=70)\n",
    "    ax2.axis('off')\n",
    "    ax2.text(0.3, 0.5, some, fontsize=70)\n",
    "\n",
    "wandb.init(project='cs6910-a2')\n",
    "wandb.log({'Sample Predictions': pyplot})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
