{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers, backend\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from matplotlib import pyplot\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML as html_print, display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up input flows\n",
    "\n",
    "# Change the dataset path to the directory where you have stored the three train, test and validation files\n",
    "\n",
    "dataset_path = \"../../dakshina_dataset_v1.0/ta/lexicons\"\n",
    "train_path = dataset_path + \"/ta.translit.sampled.train.tsv\"\n",
    "test_path = dataset_path + \"/ta.translit.sampled.test.tsv\"\n",
    "val_path = dataset_path + \"/ta.translit.sampled.dev.tsv\"\n",
    "\n",
    "train_data = ''.join([each.decode('utf-8') for each in open(train_path, 'rb')]).split()\n",
    "y_train, X_train, z_train = train_data[::3], train_data[1::3], [int(each) for each in train_data[2::3]]\n",
    "\n",
    "test_data = ''.join([each.decode('utf-8') for each in open(test_path, 'rb')]).split()\n",
    "y_test, X_test, z_test = test_data[::3], test_data[1::3], [int(each) for each in test_data[2::3]]\n",
    "\n",
    "val_data = ''.join([each.decode('utf-8') for each in open(val_path, 'rb')]).split()\n",
    "y_val, X_val, z_val = val_data[::3], val_data[1::3], [int(each) for each in val_data[2::3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the vocabulary\n",
    "\n",
    "input_vocab, output_vocab = set([\" \"]), set([\" \", \"\\t\", \"\\n\"])\n",
    "\n",
    "max_input_len, max_output_len = 0, 0\n",
    "\n",
    "for each in X_train + X_test + X_val:\n",
    "    for every in each:\n",
    "        input_vocab.add(every)\n",
    "    max_input_len = max(max_input_len, len(each))\n",
    "\n",
    "for each in y_train + y_test + y_val:\n",
    "    for every in each:\n",
    "        output_vocab.add(every)\n",
    "    max_output_len = max(max_output_len, len(each))\n",
    "\n",
    "input_vocab = sorted(list(input_vocab))\n",
    "output_vocab = sorted(list(output_vocab))\n",
    "input_v_len = len(input_vocab)\n",
    "output_v_len = len(output_vocab)\n",
    "max_output_len += 2\n",
    "\n",
    "input_inv = dict([(char, i) for i, char in enumerate(input_vocab)])\n",
    "output_inv = dict([(char, i) for i, char in enumerate(output_vocab)])\n",
    "\n",
    "reverse_inp = dict((i, char) for char, i in input_inv.items())\n",
    "reverse_out = dict((i, char) for char, i in output_inv.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data to a one hot representation\n",
    "\n",
    "def onehot(X, y):\n",
    "    \n",
    "    encoder_input_data = np.zeros((len(X), max_input_len, input_v_len), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros((len(X), max_output_len, output_v_len), dtype=\"float32\")\n",
    "    decoder_target_data = np.zeros((len(X), max_output_len, output_v_len), dtype=\"float32\")\n",
    "\n",
    "    for i, (a, b) in enumerate(zip(X, y)):\n",
    "        for t, char in enumerate(a):\n",
    "            encoder_input_data[i, t, input_inv[char]] = 1.0\n",
    "        encoder_input_data[i, t + 1 :, input_inv[\" \"]] = 1.0\n",
    "        for t, char in enumerate(\"\\t\" + b + \"\\n\"):\n",
    "            decoder_input_data[i, t, output_inv[char]] = 1.0\n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t - 1, output_inv[char]] = 1.0\n",
    "        decoder_input_data[i, t + 1 :, output_inv[\" \"]] = 1.0\n",
    "        decoder_target_data[i, t:, output_inv[\" \"]] = 1.0\n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data for RNNs with embedding layer\n",
    "\n",
    "def onehot_embed(X, y):\n",
    "    \n",
    "    encoder_input_data = np.zeros((len(X), max_input_len), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros((len(X), max_output_len), dtype=\"float32\")\n",
    "    decoder_target_data = np.zeros((len(X), max_output_len, output_v_len), dtype=\"float32\")\n",
    "\n",
    "    for i, (a, b) in enumerate(zip(X, y)):\n",
    "        for t, char in enumerate(a):\n",
    "            encoder_input_data[i, t] = input_inv[char]\n",
    "        encoder_input_data[i, t + 1 :] = input_inv[\" \"]\n",
    "        for t, char in enumerate(\"\\t\" + b + \"\\n\"):\n",
    "            decoder_input_data[i, t] = output_inv[char]\n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t - 1, output_inv[char]] = 1.0\n",
    "        decoder_input_data[i, t + 1 :] = output_inv[\" \"]\n",
    "        decoder_target_data[i, t:, output_inv[\" \"]] = 1.0\n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the RNN model\n",
    "\n",
    "def myRNN(latent_dim, num_encoders = 1, num_decoders = 1, embed_dim = None, dropout = 0.0, cell_type = 'GRU'):\n",
    "    \n",
    "    if(embed_dim == None):\n",
    "        encoder_inputs = tf.keras.Input(shape=(None, input_v_len))\n",
    "        encoder_inp = encoder_inputs\n",
    "    else:\n",
    "        encoder_inputs = tf.keras.Input(shape=(None,))\n",
    "        encoder_inp = layers.Embedding(input_dim=input_v_len, output_dim=embed_dim)(encoder_inputs)\n",
    "    \n",
    "    for ii in range(num_encoders):\n",
    "        if cell_type == 'LSTM':\n",
    "            encoder = layers.LSTM(latent_dim, return_state=True, return_sequences=True, dropout = dropout)\n",
    "            encoder_inp, state_h, state_c = encoder(encoder_inp)\n",
    "            encoder_states = [state_h, state_c]\n",
    "        else:\n",
    "            if cell_type == 'RNN':\n",
    "                encoder = layers.SimpleRNN(latent_dim, return_state=True, return_sequences=True, dropout = dropout)\n",
    "            else:\n",
    "                encoder = layers.GRU(latent_dim, return_state=True, return_sequences=True, dropout = dropout)\n",
    "            encoder_inp, state_h = encoder(encoder_inp)\n",
    "            encoder_states = [state_h]\n",
    "    \n",
    "    if(embed_dim == None):\n",
    "        decoder_inputs = tf.keras.Input(shape=(None, output_v_len))\n",
    "        decoder_out = decoder_inputs\n",
    "    else:\n",
    "        decoder_inputs = tf.keras.Input(shape=(None,))\n",
    "        decoder_out = layers.Embedding(input_dim=output_v_len, output_dim=embed_dim)(decoder_inputs)\n",
    "    \n",
    "    for ii in range(num_decoders):\n",
    "        if cell_type == 'LSTM':\n",
    "            decoder = layers.LSTM(latent_dim, return_sequences=True, return_state=True, dropout = dropout)\n",
    "            decoder_out, _, _ = decoder(decoder_out, initial_state=encoder_states)\n",
    "        else:\n",
    "            if cell_type == 'RNN':\n",
    "                decoder = layers.SimpleRNN(latent_dim, return_sequences=True, return_state=True, dropout = dropout)\n",
    "            else:\n",
    "                decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True, dropout = dropout)\n",
    "            decoder_out, _ = decoder(decoder_out, initial_state=encoder_states)\n",
    "    \n",
    "    decoder_outputs = decoder_out\n",
    "    decoder_dense = layers.Dense(output_v_len, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the encoder and decoder models\n",
    "\n",
    "def decompose(model, cell_type, latent_dim, num_encoders, num_decoders, embed_dim):\n",
    "\n",
    "    offset = 0 if embed_dim == None else 2\n",
    "\n",
    "    encoder_inputs = model.input[0]\n",
    "    _, *encoder_states = model.layers[num_encoders + 1 + offset].output    \n",
    "    encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_inputs = model.input[1]  # input_2\n",
    "    if embed_dim == None:\n",
    "        decoder_outputs = decoder_inputs\n",
    "    else:\n",
    "        decoder_outputs = model.layers[num_encoders + offset](decoder_inputs)\n",
    "\n",
    "    decoder_state_inputs = []\n",
    "    decoder_state_outputs = []\n",
    "\n",
    "    for ii in range(num_decoders):\n",
    "        if cell_type == 'LSTM':\n",
    "            temp_inputs = [tf.keras.Input(shape=(latent_dim,), name = 'decoder_0_' + str(ii)), tf.keras.Input(shape=(latent_dim,), name = 'decoder_1_' + str(ii))]\n",
    "        else:\n",
    "            temp_inputs = [tf.keras.Input(shape=(latent_dim,), name = 'decoder_' + str(ii))]\n",
    "        decoder_state_inputs += temp_inputs\n",
    "\n",
    "        decoder = model.layers[num_encoders + 2 + ii + offset]\n",
    "        decoder_outputs, *temp_states = decoder(decoder_outputs, initial_state=temp_inputs)\n",
    "        decoder_state_outputs += temp_states\n",
    "\n",
    "    decoder_dense = model.layers[num_encoders + num_decoders + 2 + offset]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_state_outputs)\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the sequence\n",
    "\n",
    "def decode_sequence(input_seq, encoder_model, decoder_model, num_decoders, embed_dim):\n",
    "    \n",
    "    enc_states = [encoder_model.predict(input_seq)] * num_decoders\n",
    "\n",
    "    if(embed_dim == None):\n",
    "        target_seq = np.zeros((1, 1, output_v_len))\n",
    "        target_seq[0, 0, output_inv[\"\\t\"]] = 1.0\n",
    "    else:\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = output_inv[\"\\t\"]\n",
    "\n",
    "    stop_condition = False\n",
    "    final_ans = \"\"\n",
    "    while not stop_condition:\n",
    "        output_chars, *h = decoder_model.predict([target_seq] + enc_states)\n",
    "        enc_states = h\n",
    "        \n",
    "        sampled_char_index = np.argmax(output_chars[0, -1, :])\n",
    "        sampled_char = reverse_out[sampled_char_index]\n",
    "        final_ans += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(final_ans) > max_output_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        if(embed_dim == None):\n",
    "            target_seq = np.zeros((1, 1, output_v_len))\n",
    "            target_seq[0, 0, sampled_char_index] = 1.0\n",
    "        else:\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_char_index\n",
    "    \n",
    "    return final_ans[:-1]\n",
    "\n",
    "def get_acc(input_seq, test_seq, encoder_model, decoder_model, num_decoders, embed_dim):\n",
    "    n = len(input_seq)\n",
    "    \n",
    "    enc_states = [encoder_model.predict(input_seq)] * num_decoders\n",
    "    \n",
    "    if(embed_dim == None):\n",
    "        target_seq = np.zeros((n, 1, output_v_len))\n",
    "        target_seq[:, 0, output_inv[\"\\t\"]] = 1.0\n",
    "    else:\n",
    "        target_seq = np.zeros((n, 1))\n",
    "        target_seq[:, 0] = output_inv[\"\\t\"]\n",
    "    \n",
    "    final_ans = [\"\" for _ in range(n)]\n",
    "    for _ in range(max_output_len):\n",
    "        output_chars, *h = decoder_model.predict([target_seq] + enc_states)\n",
    "        enc_states = h\n",
    "        \n",
    "        sampled_char_index = np.argmax(output_chars[:, -1, :], axis=1)\n",
    "        sampled_char = [reverse_out[sampled_char_index[ii]] for ii in range(n)]\n",
    "        final_ans = [ x + y for x, y in zip(final_ans, sampled_char)]\n",
    "        \n",
    "        if(embed_dim == None):\n",
    "            target_seq = np.zeros((n, 1, output_v_len))\n",
    "            target_seq[range(n), 0, sampled_char_index] = 1.0\n",
    "        else:\n",
    "            target_seq = np.zeros((n, 1))\n",
    "            target_seq[:, 0] = sampled_char_index\n",
    "    \n",
    "    final_ans = [x.split('\\n')[0] for x in final_ans]\n",
    "    \n",
    "    final_acc = sum([x == y for x, y in zip(final_ans, test_seq)]) / n\n",
    "    return final_ans, final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size=64, epochs=25, embed_dim=None, wandb_cb = True):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    if embed_dim == None:\n",
    "        aa, bb, cc = onehot(X_train, y_train)\n",
    "        dd, ee, ff = onehot(X_val, y_val)\n",
    "    else:\n",
    "        aa, bb, cc = onehot_embed(X_train, y_train)\n",
    "        dd, ee, ff = onehot_embed(X_val, y_val)\n",
    "        \n",
    "    if wandb_cb:   \n",
    "        model.fit([aa, bb], cc, batch_size=batch_size, epochs=epochs, validation_data = ([dd, ee], ff), callbacks=[WandbCallback()])\n",
    "    else:\n",
    "        model.fit([aa, bb], cc, batch_size=batch_size, epochs=epochs, validation_data = ([dd, ee], ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'word_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'hidden_layer_size': {\n",
    "            'values': [ 16, 32, 64, 256],\n",
    "        },\n",
    "        'num_encoders': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'num_decoders': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.0, 0.2, 0.3]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['RNN', 'LSTM', 'GRU']\n",
    "        },\n",
    "        'num_epochs': {\n",
    "            'values': [5, 10, 15]\n",
    "        },\n",
    "        'embed_dim' : {\n",
    "            'values': [None, 64, 256, 512]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity = '0x2e4', project = 'cs6910-a3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run():\n",
    "    default_config = {'hidden_layer_size': 16, 'num_encoders': 1, 'num_decoders': 1, 'dropout': 0.0, 'cell_type': 'RNN', 'num_epochs': 30, 'embed_dim' : None}\n",
    "\n",
    "    run = wandb.init(project='cs6910-a3', config=default_config)\n",
    "    config = wandb.config\n",
    "\n",
    "    model = myRNN(latent_dim=config.hidden_layer_size, num_encoders = config.num_encoders, num_decoders = config.num_decoders, dropout = config.dropout, cell_type = config.cell_type, embed_dim = config.embed_dim)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Nadam()\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    train(model, epochs=config.num_epochs, embed_dim = config.embed_dim)\n",
    "    \n",
    "    enc_model, dec_model = decompose(model, config.cell_type, config.hidden_layer_size, config.num_encoders, config.num_decoders, config.embed_dim)\n",
    "    \n",
    "    if config.embed_dim == None:\n",
    "        test_in, test_out, _ = onehot(X_test, y_test)\n",
    "    else:\n",
    "        test_in, test_out, _ = onehot_embed(X_test, y_test)\n",
    "    _, word_acc = get_acc(test_in, y_test, enc_model, dec_model, config.num_decoders, config.embed_dim)\n",
    "    \n",
    "    wandb.log({ 'word_acc' : word_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the best model\n",
    "\n",
    "best_model = myRNN(cell_type = 'GRU', latent_dim = 256, dropout = 0.2, num_encoders = 2, num_decoders = 3, embed_dim = 256)\n",
    "\n",
    "train(best_model, epochs = 5, embed_dim = 256, wandb_cb=False)\n",
    "\n",
    "encoder_model, decoder_model = decompose(best_model, 'GRU', 256, 2, 3, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "test_in, test_out, _ = onehot_embed(X_test, y_test)\n",
    "test_pred, test_acc = get_acc(test_in, y_test, encoder_model, decoder_model, 3, 400)\n",
    "\n",
    "print(test_acc)\n",
    "\n",
    "test_dict = { 'Input' : X_test, 'Prediction' : test_pred, 'True Output' : y_test}\n",
    "vanilla = pd.DataFrame(data=test_dict)\n",
    "\n",
    "vanilla.to_csv('predictions_vanilla.csv', index=False)\n",
    "\n",
    "vanilla_sample = vanilla.sample(10, replace=False)\n",
    "vanilla_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=[50, 100])\n",
    "all_classes = list(test_generator.class_indices.keys())\n",
    "\n",
    "ax = pyplot.subplot(11, 3, 1)\n",
    "ax1 = pyplot.subplot(11, 3, 2)\n",
    "ax2 = pyplot.subplot(11, 3, 3)\n",
    "ax.axis('off')\n",
    "ax.text(0.3, 0.5, \"Sample Image\", fontsize=70)\n",
    "ax1.axis('off')\n",
    "ax1.text(0.3, 0.5, \"Prediction\", fontsize=70)\n",
    "ax2.axis('off')\n",
    "ax2.text(0.3, 0.5, \"True Class\", fontsize=70)\n",
    "\n",
    "for some in os.listdir(test_path):\n",
    "    idx = test_generator.class_indices[some]\n",
    "    new_path = test_path + \"/\" + some\n",
    "    img_path = new_path + \"/\" + os.listdir(new_path)[0]\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path,\n",
    "                                                target_size=(max_shape[0],\n",
    "                                                             max_shape[1]))\n",
    "    img_np = np.asarray(img)\n",
    "    ax = pyplot.subplot(11, 3, 3 * idx + 4)\n",
    "    ax1 = pyplot.subplot(11, 3, 3 * idx + 5)\n",
    "    ax2 = pyplot.subplot(11, 3, 3 * idx + 6)\n",
    "    ax.imshow(img_np)\n",
    "    ax1.axis('off')\n",
    "    ax1.text(0.3, 0.5, all_classes[y_pred[200 * idx]], fontsize=70)\n",
    "    ax2.axis('off')\n",
    "    ax2.text(0.3, 0.5, some, fontsize=70)\n",
    "\n",
    "wandb.init(project='cs6910-a2')\n",
    "wandb.log({'Sample Predictions': pyplot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The attention layer\n",
    "\n",
    "class AttentionLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = backend.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = backend.expand_dims(backend.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = backend.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = backend.squeeze(backend.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = backend.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = backend.sum(encoder_out_seq * backend.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = backend.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = backend.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = backend.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = backend.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the RNN model with attention\n",
    "\n",
    "def myRNN_attn(latent_dim, embed_dim = None, dropout = 0.0, cell_type = 'GRU'):\n",
    "    \n",
    "    if(embed_dim == None):\n",
    "        encoder_inputs = tf.keras.Input(shape=(None, input_v_len))\n",
    "        encoder_inp = encoder_inputs\n",
    "    else:\n",
    "        encoder_inputs = tf.keras.Input(shape=(None,))\n",
    "        encoder_inp = layers.Embedding(input_dim=input_v_len, output_dim=embed_dim)(encoder_inputs)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder = layers.LSTM(latent_dim, return_state=True, return_sequences=True, dropout = dropout)\n",
    "        encoder_inp, state_h, state_c = encoder(encoder_inp)\n",
    "        encoder_states = [state_h, state_c]\n",
    "    else:\n",
    "        if cell_type == 'RNN':\n",
    "            encoder = layers.SimpleRNN(latent_dim, return_state=True, return_sequences=True, dropout = dropout)\n",
    "        else:\n",
    "            encoder = layers.GRU(latent_dim, return_state=True, return_sequences=True, dropout = dropout)\n",
    "        encoder_inp, state_h = encoder(encoder_inp)\n",
    "        encoder_states = [state_h]\n",
    "    \n",
    "    if(embed_dim == None):\n",
    "        decoder_inputs = tf.keras.Input(shape=(None, output_v_len))\n",
    "        decoder_out = decoder_inputs\n",
    "    else:\n",
    "        decoder_inputs = tf.keras.Input(shape=(None,))\n",
    "        decoder_out = layers.Embedding(input_dim=output_v_len, output_dim=embed_dim)(decoder_inputs)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        decoder = layers.LSTM(latent_dim, return_sequences=True, return_state=True, dropout = dropout)\n",
    "        decoder_out, _, _ = decoder(decoder_out, initial_state=encoder_states)\n",
    "    else:\n",
    "        if cell_type == 'RNN':\n",
    "            decoder = layers.SimpleRNN(latent_dim, return_sequences=True, return_state=True, dropout = dropout)\n",
    "        else:\n",
    "            decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True, dropout = dropout)\n",
    "        decoder_out, _ = decoder(decoder_out, initial_state=encoder_states)\n",
    "    \n",
    "    decoder_outputs = decoder_out\n",
    "    \n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, _ = attn_layer([encoder_inp, decoder_outputs])\n",
    "    decoder_concat_input = layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "    \n",
    "    decoder_dense = layers.Dense(output_v_len, activation=\"softmax\")\n",
    "    decoder_preds = decoder_dense(decoder_concat_input)\n",
    "    \n",
    "    model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_preds)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the best attention model\n",
    "\n",
    "best_attn_model = myRNN_attn(cell_type = 'GRU', latent_dim = 256, dropout = 0.2, embed_dim = 256)\n",
    "\n",
    "train(best_attn_model, epochs = 5, embed_dim = 256, wandb_cb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the encoder and decoder models\n",
    "\n",
    "cell_type = 'GRU'\n",
    "latent_dim = 256\n",
    "embed_dim = 256\n",
    "\n",
    "offset = 0 if embed_dim == None else 2\n",
    "\n",
    "encoder_inputs = best_attn_model.input[0]\n",
    "encoder_out, *encoder_states = best_attn_model.layers[2 + offset].output    \n",
    "encoder_attn_model = tf.keras.Model(encoder_inputs, [encoder_out] + encoder_states)\n",
    "\n",
    "decoder_inputs = best_attn_model.input[1]  # input_2\n",
    "if embed_dim == None:\n",
    "    decoder_out = decoder_inputs\n",
    "else:\n",
    "    decoder_out = best_attn_model.layers[1 + offset](decoder_inputs)\n",
    "\n",
    "decoder_state_inputs = []\n",
    "decoder_state_outputs = []\n",
    "\n",
    "if cell_type == 'LSTM':\n",
    "    temp_inputs = [tf.keras.Input(shape=(latent_dim,), name = 'decoder_0_0'), tf.keras.Input(shape=(latent_dim,), name = 'decoder_1_0')]\n",
    "else:\n",
    "    temp_inputs = [tf.keras.Input(shape=(latent_dim,), name = 'decoder_0')]\n",
    "decoder_state_inputs += temp_inputs\n",
    "\n",
    "decoder = best_attn_model.layers[3 + offset]\n",
    "decoder_outputs, *temp_states = decoder(decoder_out, initial_state=temp_inputs)\n",
    "decoder_state_outputs += temp_states\n",
    "\n",
    "attn_layer = best_attn_model.layers[4 + offset]\n",
    "attn_inp = tf.keras.Input(shape=(encoder_out.shape[1],encoder_out.shape[2]))\n",
    "attn_out, attn_states = attn_layer([attn_inp, decoder_outputs])\n",
    "decoder_concat_input = layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "                                                                                             \n",
    "decoder_dense = best_attn_model.layers[6 + offset]\n",
    "decoder_preds = decoder_dense(decoder_concat_input)\n",
    "\n",
    "decoder_attn_model = tf.keras.Model([decoder_inputs] + decoder_state_inputs + [attn_inp], [decoder_preds] + decoder_state_outputs + [attn_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the sequence\n",
    "\n",
    "def decode_sequence_attn(input_seq):\n",
    "    \n",
    "    encoder_out, *enc_states = encoder_attn_model.predict(input_seq)\n",
    "\n",
    "    if(embed_dim == None):\n",
    "        target_seq = np.zeros((1, 1, output_v_len))\n",
    "        target_seq[0, 0, output_inv[\"\\t\"]] = 1.0\n",
    "    else:\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = output_inv[\"\\t\"]\n",
    "\n",
    "    stop_condition = False\n",
    "    final_ans = \"\"\n",
    "    all_attn = []\n",
    "    while not stop_condition:\n",
    "        output_chars, *h, attn_wts = decoder_attn_model.predict([target_seq] + enc_states + [encoder_out])\n",
    "        enc_states = h\n",
    "        all_attn += [attn_wts]\n",
    "        \n",
    "        sampled_char_index = np.argmax(output_chars[0, -1, :])\n",
    "        sampled_char = reverse_out[sampled_char_index]\n",
    "        final_ans += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(final_ans) > max_output_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        if(embed_dim == None):\n",
    "            target_seq = np.zeros((1, 1, output_v_len))\n",
    "            target_seq[0, 0, sampled_char_index] = 1.0\n",
    "        else:\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_char_index\n",
    "    \n",
    "    return final_ans[:-1], all_attn[:-1]\n",
    "\n",
    "def get_acc_attn(input_seq, test_seq):\n",
    "    n = len(input_seq)\n",
    "    \n",
    "    encoder_out, *enc_states = encoder_attn_model.predict(input_seq)\n",
    "    \n",
    "    if(embed_dim == None):\n",
    "        target_seq = np.zeros((n, 1, output_v_len))\n",
    "        target_seq[:, 0, output_inv[\"\\t\"]] = 1.0\n",
    "    else:\n",
    "        target_seq = np.zeros((n, 1))\n",
    "        target_seq[:, 0] = output_inv[\"\\t\"]\n",
    "    \n",
    "    final_ans = [\"\" for _ in range(n)]\n",
    "    for _ in range(max_output_len):\n",
    "        output_chars, *h, attn_wts = decoder_attn_model.predict([target_seq] + enc_states + [encoder_out])\n",
    "        enc_states = h\n",
    "        \n",
    "        sampled_char_index = np.argmax(output_chars[:, -1, :], axis=1)\n",
    "        sampled_char = [reverse_out[sampled_char_index[ii]] for ii in range(n)]\n",
    "        final_ans = [ x + y for x, y in zip(final_ans, sampled_char)]\n",
    "        \n",
    "        if(embed_dim == None):\n",
    "            target_seq = np.zeros((n, 1, output_v_len))\n",
    "            target_seq[range(n), 0, sampled_char_index] = 1.0\n",
    "        else:\n",
    "            target_seq = np.zeros((n, 1))\n",
    "            target_seq[:, 0] = sampled_char_index\n",
    "    \n",
    "    final_ans = [x.split('\\n')[0] for x in final_ans]\n",
    "    \n",
    "    final_acc = sum([x == y for x, y in zip(final_ans, test_seq)]) / n\n",
    "    return final_ans, final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "test_in, test_out, _ = onehot_embed(X_test, y_test)\n",
    "test_pred, test_acc = get_acc_attn(test_in, y_test)\n",
    "\n",
    "print(test_acc)\n",
    "\n",
    "test_dict = { 'Input' : X_test, 'Prediction' : test_pred, 'True Output' : y_test}\n",
    "attention = pd.DataFrame(data=test_dict)\n",
    "\n",
    "attention.to_csv('predictions_attention.csv', index=False)\n",
    "\n",
    "attention_sample = attention.sample(10, replace=False)\n",
    "attention_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectivity Visualization\n",
    "\n",
    "\n",
    "# get html element\n",
    "def cstr(s, color='black'):\n",
    "        return \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
    "\n",
    "# print html\n",
    "def print_color(t):\n",
    "    okay = ''.join([cstr(ti, color=ci) for ti,ci in t])\n",
    "    okay = \"<p style=text-align:center;font-size:30px>\" + okay + \"</p>\"\n",
    "    display(html_print(okay))\n",
    "\n",
    "# get appropriate color for value\n",
    "def get_clr(value):\n",
    "    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
    "            '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
    "            '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
    "            '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
    "    value = int((value * 100) / 5)\n",
    "    return colors[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectivity Visualization\n",
    "\n",
    "ii = 642\n",
    "\n",
    "res, res1 = decode_sequence_attn(test_in[ii: ii + 1])\n",
    "inp = X_test[ii]\n",
    "m = len(inp)\n",
    "n = len(res)\n",
    "res1 = [res1[jj][0, 0, :m] for jj in range(n)]\n",
    "\n",
    "gap = [2, 5, 8, 10, 12]\n",
    "\n",
    "def fn():\n",
    "    for pos in range(n):\n",
    "        text_colours = [[], []]\n",
    "        pos1 = pos - 1 if pos in gap else pos\n",
    "        for kk in range(n):\n",
    "            text = (res[kk], get_clr(0.99 if kk == pos1 else 0))\n",
    "            text_colours[0].append(text)\n",
    "        for kk in range(m):\n",
    "            text = (inp[kk], get_clr(res1[pos][kk]))\n",
    "            text_colours[1].append(text)\n",
    "        clear_output()\n",
    "        print_color(text_colours[0])\n",
    "        print_color(text_colours[1])\n",
    "        time.sleep(1)\n",
    "    clear_output()\n",
    "    \n",
    "fn()\n",
    "#print(list(res)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-amateur",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
